{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef52e65-464a-4b66-94b0-a156743b9d03",
   "metadata": {},
   "source": [
    "# Utility API Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72231ea5-ce39-46c8-9277-fa6a3659c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "import io\n",
    "from pandas import json_normalize\n",
    "import json, requests, urllib, io\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import gzip\n",
    "import sys\n",
    "from datetime import date\n",
    "from src.aws import get_secret\n",
    "\n",
    "\n",
    "def get_active_meters(API_TOKEN):\n",
    "    url = 'https://utilityapi.com/api/v2/meters'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    r = requests.get(url, headers=headers)\n",
    "    download = json.loads(r.text)\n",
    "    \n",
    "    active_meters=[]\n",
    "    \n",
    "    for i in range(len(download['meters'])):\n",
    "        if download['meters'][i]['is_activated']==True and download['meters'][i]['is_archived']==False :\n",
    "            active_meters.append(download['meters'][i]['uid'])\n",
    "    return active_meters\n",
    "\n",
    "def get_bills(API_TOKEN, meter_uid):\n",
    "    url =f'https://utilityapi.com/api/v2/files/meters_bills_csv?meters={meter_uid}'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    download = requests.get(url, headers=headers).content\n",
    "    return pd.read_csv(io.StringIO(download.decode('utf-8')), error_bad_lines=False)\n",
    "\n",
    "def test_demand_kw_in_bills(API_TOKEN):\n",
    "    no_demand_kw=[]\n",
    "    all_active = get_active_meters(API_TOKEN)\n",
    "    for i in all_active:\n",
    "        try:\n",
    "            get_bills(i)['Demand_kw']\n",
    "            return_code=0\n",
    "        except Exception as e:\n",
    "            return_code=1\n",
    "#             print(e)\n",
    "        if return_code==1:\n",
    "            no_demand_kw.append(i)        \n",
    "    return no_demand_kw\n",
    "\n",
    "\n",
    "# send bills dataframe to S3\n",
    "\n",
    "def send_bills_to_s3_with_demand_kw(API_TOKEN, meter_uid):\n",
    "    \n",
    "    cols = [ \n",
    "            'meter_uid','utility'\n",
    "            ,'utility_service_id' ,'utility_billing_account'\n",
    "            ,'utility_service_address','utility_meter_number'\n",
    "            ,'utility_tariff_name','bill_start_date'\n",
    "            ,'bill_end_date','bill_days'\n",
    "            ,'bill_statement_date','bill_total_kWh'\n",
    "            ,'bill_total','bill_volume','bill_total_unit',  'Demand_kw'\n",
    "           ]\n",
    "    \n",
    "    df=get_bills(API_TOKEN, meter_uid)[cols]\n",
    "    \n",
    "    print(f'Loading {len(df)} Rows to S3 for meter_uid {meter_uid}')\n",
    "    \n",
    "    load_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    print(\"Load Date:\", load_date)\n",
    "    \n",
    "    session = boto3.session.Session(profile_name=\"data-arch\", )\n",
    "    s3_client = session.client(\"s3\", use_ssl=False)    \n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    gz_buffer = io.BytesIO()\n",
    "    \n",
    "\n",
    "    with gzip.GzipFile(mode='w', fileobj=gz_buffer) as gz_file:\n",
    "        gz_file.write(bytes(csv_buffer.getvalue(), 'utf-8'))\n",
    "    try:\n",
    "        s3_client.put_object(Bucket='utility-api', Key=f\"\"\"bills/{load_date}/meter_uid_{meter_uid}_bills.csv.gz\"\"\", Body=gz_buffer.getvalue())\n",
    "        return_code = 0\n",
    "    except Exception as e:\n",
    "        return_code = 1\n",
    "        print(e)\n",
    "    return return_code\n",
    "\n",
    "def send_bills_to_s3_without_demand_kw(API_TOKEN, meter_uid):\n",
    "    \n",
    "    cols = [ \n",
    "            'meter_uid','utility'\n",
    "            ,'utility_service_id' ,'utility_billing_account'\n",
    "            ,'utility_service_address','utility_meter_number'\n",
    "            ,'utility_tariff_name','bill_start_date'\n",
    "            ,'bill_end_date','bill_days'\n",
    "            ,'bill_statement_date','bill_total_kWh'\n",
    "            ,'bill_total','bill_volume','bill_total_unit',  #'Demand_kw'\n",
    "           ]\n",
    "    \n",
    "    df=get_bills(API_TOKEN, meter_uid)[cols]\n",
    "    \n",
    "    print(f'Loading {len(df)} Rows to S3 for meter_uid {meter_uid}')\n",
    "    \n",
    "    load_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    print(\"Load Date:\", load_date)\n",
    "    \n",
    "    session = boto3.session.Session(profile_name=\"data-arch\", )\n",
    "    s3_client = session.client(\"s3\", use_ssl=False)    \n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    gz_buffer = io.BytesIO()\n",
    "    \n",
    "\n",
    "    with gzip.GzipFile(mode='w', fileobj=gz_buffer) as gz_file:\n",
    "        gz_file.write(bytes(csv_buffer.getvalue(), 'utf-8'))\n",
    "    try:\n",
    "        s3_client.put_object(Bucket='utility-api', Key=f\"\"\"bills/{load_date}/meter_uid_{meter_uid}_bills.csv.gz\"\"\", Body=gz_buffer.getvalue())\n",
    "        return_code = 0\n",
    "    except Exception as e:\n",
    "        return_code = 1\n",
    "        print(e)\n",
    "    return return_code\n",
    "\n",
    "\n",
    "def get_intervals(API_TOKEN, meter_uid):\n",
    "    url = f'https://utilityapi.com/api/v2/files/intervals_csv?meters={meter_uid}'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    download = requests.get(url, headers=headers).content\n",
    "    return pd.read_csv(io.StringIO(download.decode('utf-8')), error_bad_lines=False)\n",
    "\n",
    "\n",
    "# Send intervals dataframe to s3 \n",
    "\n",
    "def send_intervals_to_s3(API_TOKEN, meter_uid):\n",
    "    df = get_intervals(API_TOKEN, meter_uid)\n",
    "    df.astype = {\n",
    "        'meter_uid':int, \n",
    "        'utility':str, \n",
    "        'utility_service_id':int, \n",
    "        'utility_service_address':str,\n",
    "        'utility_meter_number':int, \n",
    "        'utility_tariff_name':str, \n",
    "        'interval_start':str,\n",
    "        'interval_end':str, \n",
    "        'interval_kWh':int, \n",
    "        'net_kWh':int, \n",
    "        'source':str, \n",
    "        'updated':str,\n",
    "        'interval_timezone':str\n",
    "    }\n",
    "    \n",
    "    print(f'Loading {len(df)} Rows to S3 for meter_uid {meter_uid}')\n",
    "    \n",
    "    load_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    print(\"Load Date:\", load_date)\n",
    "    \n",
    "    session = boto3.session.Session(profile_name=\"data-arch\", )\n",
    "    s3_client = session.client(\"s3\", use_ssl=False)    \n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    gz_buffer = io.BytesIO()\n",
    "    \n",
    "\n",
    "    with gzip.GzipFile(mode='w', fileobj=gz_buffer) as gz_file:\n",
    "        gz_file.write(bytes(csv_buffer.getvalue(), 'utf-8'))\n",
    "    try:\n",
    "        s3_client.put_object(Bucket='utility-api', Key=f\"\"\"intervals/{load_date}/meter_uid_{meter_uid}_intervals.csv.gz\"\"\", Body=gz_buffer.getvalue())\n",
    "        return_code = 0\n",
    "    except Exception as e:\n",
    "        return_code = 1\n",
    "        print(e)\n",
    "    return return_code\n",
    "\n",
    "\n",
    "def test_demand_kw_in_bills(API_TOKEN):\n",
    "    no_demand_kw=[]\n",
    "    all_active = get_active_meters(API_TOKEN)\n",
    "    for i in all_active:\n",
    "        try:\n",
    "            get_bills(i)['Demand_kw']\n",
    "            return_code=0\n",
    "        except Exception as e:\n",
    "            return_code=1\n",
    "#             print(e)\n",
    "        if return_code==1:\n",
    "            no_demand_kw.append(i)        \n",
    "    return no_demand_kw\n",
    "    \n",
    "\n",
    "def load_s3(API_TOKEN):\n",
    "    meter_list_all=get_active_meters(API_TOKEN)\n",
    "    \n",
    "    meters_no_Demand_kw = test_demand_kw_in_bills(API_TOKEN)\n",
    "    \n",
    "    meters_with_demand_kw = [x for x in meter_list_all if x not in meters_no_Demand_kw]\n",
    "    print(\"\")\n",
    "    print(\"Loading Bills data to S3 ...\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    for i in meters_no_Demand_kw:\n",
    "        send_bills_to_s3_without_demand_kw(API_TOKEN, i)\n",
    "    \n",
    "    print(f\"Loaded {len(meters_no_Demand_kw)} files with no Demand_kw field\")\n",
    "    \n",
    "    for i in meters_with_demand_kw:\n",
    "        send_bills_to_s3_with_demand_kw(API_TOKEN, i)\n",
    "    \n",
    "    print(f\"Loaded {len(meters_with_demand_kw)} files with Demand_kw field\")\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Loading Intervals data to S3 ...\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    for i in meter_list_all:\n",
    "        send_intervals_to_s3(API_TOKEN, i)\n",
    "        \n",
    "\n",
    "def execute_load_s3():\n",
    "    try:\n",
    "        API_TOKEN=get_secret('utility-api-token').get('API_TOKEN') \n",
    "        load_s3(API_TOKEN)\n",
    "        return_code=0\n",
    "    except Exception as e:\n",
    "        return_code=1\n",
    "        print(e)\n",
    "    return return_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16d0fd-291c-4728-ac6f-b1c5e98c61e4",
   "metadata": {},
   "source": [
    "# Load Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c89e0cc-d7cf-4bfe-ab20-c72d7c357cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_load_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b1205-5052-4a14-a109-e21d4064f42b",
   "metadata": {},
   "source": [
    "# Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee9a8067-1018-4e24-8dbd-b9974225b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowflake_connection(schema):\n",
    "    \n",
    "    creds = get_secret('utility-database-credentials')\n",
    "    \n",
    "    con = snowflake.connector.connect(\n",
    "        user=creds.get(\"user\"),\n",
    "        password=creds.get(\"password\"),\n",
    "        account=cred.get(\"acount\"),\n",
    "        warehouse=cred.get(\"warehouse\"),\n",
    "        database=cred.get(\"database\"),\n",
    "        schema=schema,\n",
    "        role=cred.get('role')\n",
    "        )\n",
    "    return con\n",
    "\n",
    "def load_data_to_snowflake(utility_file):\n",
    "    \n",
    "    load_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    schema='STAGE'\n",
    "    external_stage='utility_api_stage'\n",
    "     \n",
    "    if utility_file=='bills':\n",
    "        utility_file_length=16\n",
    "        table='BILLS_RAW_SRC'\n",
    "        \n",
    "        print(\"\")\n",
    "        print(f\"loading {utility_file} data for files ingested on {load_date}\")\n",
    "        print(\"\")\n",
    "        con=snowflake_connection(schema)\n",
    "        cs=con.cursor()\n",
    "        print(f\"Truncating {schema}.{table} Prior to Load\")\n",
    "        cs.execute(f\"\"\"truncate {schema}.{table};\"\"\")\n",
    "        print(f\"Succesfully Truncated {schema}.{table} Prior to load\")\n",
    "        print(\"\")\n",
    "        print(f\"Loading {schema}.{table} \")\n",
    "\n",
    "\n",
    "\n",
    "        cols =\", \".join([f\"${i}\" for i in range(1,utility_file_length+1)])\n",
    "\n",
    "        query = f\"\"\"COPY INTO {schema}.{table}\n",
    "                    FROM (\n",
    "                    SELECT {cols}\n",
    "                    FROM @{external_stage}/{utility_file}/{load_date}/)\n",
    "                    ENFORCE_LENGTH = True\n",
    "                        FILE_FORMAT = (\n",
    "                        ERROR_ON_COLUMN_COUNT_MISMATCH=FALSE\n",
    "                        type = csv \n",
    "                        FIELD_DELIMITER = ','\n",
    "                        COMPRESSION = AUTO\n",
    "                        SKIP_HEADER = 1\n",
    "                        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "                        EMPTY_FIELD_AS_NULL = True\n",
    "                        NULL_IF = ('NULL','null','','None')\n",
    "                        VALIDATE_UTF8 = False\n",
    "                        )\n",
    "                        ;\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "        results=cs.execute(query)\n",
    "        rows=cs.fetchall()\n",
    "        df=pd.DataFrame(rows, columns= [desc[0] for desc in cs.description])\n",
    "\n",
    "        print(f\"Succesfully loaded {utility_file} data into {schema}.{table} with {len(df)} files \")\n",
    "           \n",
    "    elif utility_file=='intervals':\n",
    "        utility_file_length=13\n",
    "        table='INTERVALS_RAW_SRC'\n",
    "        \n",
    "        print(\"\")\n",
    "        print(f\"loading {utility_file} data for files ingested on {load_date}\")\n",
    "        print(\"\")\n",
    "        con=snowflake_connection(schema)\n",
    "        cs=con.cursor()\n",
    "        print(f\"Truncating {schema}.{table} Prior to Load\")\n",
    "        cs.execute(f\"\"\"truncate {schema}.{table};\"\"\")\n",
    "        print(f\"Succesfully Truncated {schema}.{table} Prior to load\")\n",
    "        print(\"\")\n",
    "        print(f\"Loading {schema}.{table} \")\n",
    "\n",
    "\n",
    "\n",
    "        cols =\", \".join([f\"${i}\" for i in range(1,utility_file_length+1)])\n",
    "\n",
    "        query = f\"\"\"COPY INTO {schema}.{table}\n",
    "                    FROM (\n",
    "                    SELECT {cols}\n",
    "                    FROM @{external_stage}/{utility_file}/{load_date}/)\n",
    "                    ENFORCE_LENGTH = True\n",
    "                        FILE_FORMAT = (\n",
    "                        ERROR_ON_COLUMN_COUNT_MISMATCH=FALSE\n",
    "                        type = csv \n",
    "                        FIELD_DELIMITER = ','\n",
    "                        COMPRESSION = AUTO\n",
    "                        SKIP_HEADER = 1\n",
    "                        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "                        EMPTY_FIELD_AS_NULL = True\n",
    "                        NULL_IF = ('NULL','null','','None')\n",
    "                        VALIDATE_UTF8 = False\n",
    "                        )\n",
    "                        ;\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "        results=cs.execute(query)\n",
    "        rows=cs.fetchall()\n",
    "        df=pd.DataFrame(rows, columns= [desc[0] for desc in cs.description])\n",
    "\n",
    "        print(f\"Succesfully loaded {utility_file} data into {schema}.{table} with {len(df)} files \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e07dca33-11a1-4a14-a5ff-76d28392106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data_to_snowflake('bills')\n",
    "# load_data_to_snowflake('intervals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544d367-ed3e-4c36-ac22-2e6049a264ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
